{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_module_naive(layer,color_channels,kernel_output):\n",
    "    mu=0\n",
    "    sigma=0.1\n",
    "    # 1*1 Convolution Layer\n",
    "    filter_1_1=tf.Variable(tf.truncated_normal([1,1,color_channels,kernel_output], mu, sigma))\n",
    "    block_conv1=tf.nn.conv2d(layer,filter_1_1,strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    # 3*3 Convolution Layer\n",
    "    filter_3_1=tf.Variable(tf.truncated_normal([3,3,color_channels,kernel_output], mu, sigma))\n",
    "    block_conv3=tf.nn.conv2d(layer,filter_3_1,strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    # 5*5 Convolution Layer\n",
    "    filter_5_1=tf.Variable(tf.truncated_normal([5,5,color_channels,kernel_output], mu, sigma))\n",
    "    block_conv5=tf.nn.conv2d(layer,filter_5_1,strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    # Average Pooling followed by 1*1 Convolution Layer\n",
    "    average_pool=tf.nn.avg_pool(layer,ksize=[1,2,2,1],strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    filter_1_2=tf.Variable(tf.truncated_normal([1,1,color_channels,kernel_output],mu,sigma))\n",
    "    block_avgpool_conv1=tf.nn.conv2d(average_pool,filter_1_2,strides=[1,1,1,1], padding='SAME')\n",
    "    \n",
    "    # Concatenating layers\n",
    "    bias=tf.Variable(tf.truncated_normal([color_channels+3*kernel_output], mu, sigma))\n",
    "    x=tf.concat([block_conv1,block_conv3,block_conv5,block_avgpool],axis=3)\n",
    "    x=tf.nn.bias_add(x,bias)\n",
    "    \n",
    "    return tf.nn.relu(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_module_googlenet(layer):\n",
    "    mu=0\n",
    "    sigma=0.1\n",
    "    \n",
    "    def convolution(layer,weight,bias):\n",
    "        # W- Weight [Filter height, Filter width, color_channels, k_output]\n",
    "        temp=tf.nn.conv2d(layer,weight,strides=[1,1,1,1],padding='SAME')\n",
    "        return tf.nn.bias_add(temp,bias)\n",
    "    \n",
    "    def maxpool_3x3(layer):\n",
    "        return tf.nn.max_pool(layer,ksize=[1,3,3,1],strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    def relu(layer):\n",
    "        return tf.nn.relu(layer)\n",
    "        \n",
    "    # Weights,Biases\n",
    "    # Three 1*1 Convolution Layers- Block One\n",
    "    b1_conv_weight_1x1_1=tf.Variable(tf.truncated_normal([1,1,1,32],mu,sigma))\n",
    "    b1_conv_bias_1x1_1=tf.Variable(tf.zeros([32]))\n",
    "    \n",
    "    b1_conv_weight_1x1_2=tf.Variable(tf.truncated_normal([1,1,1,16],mu,sigma))\n",
    "    b1_conv_bias_1x1_2=tf.Variable(tf.zeros([16]))\n",
    "    \n",
    "    b1_conv_weight_1x1_3=tf.Variable(tf.truncated_normal([1,1,1,16],mu,sigma))\n",
    "    b1_conv_bias_1x1_3=tf.Variable(tf.zeros([16]))\n",
    "    \n",
    "    # 3*3  Convolution Layer that follows b_1_conv_2- Block Two\n",
    "    b2_conv_weight_3x3=tf.Variable(tf.truncated_normal([3,3,16,32],mu,sigma))\n",
    "    c=tf.Variable(tf.zeros([32]))\n",
    "    \n",
    "    # 5*5 Convolution Layer that follows b1_conv_3- Block Two\n",
    "    b2_conv_weight_5x5=tf.Variable(tf.truncated_normal([5,5,16,32],mu,sigma))\n",
    "    b2_conv_bias_5x5=tf.Variable(tf.zeros([32]))\n",
    "    \n",
    "    # 1*1 Convolution Layer that follows a 3*3 maxpool layer- Block Two\n",
    "    b2_conv_weight_1x1=tf.Variable(tf.truncated_normal([1,1,1,32],mu,sigma))\n",
    "    b2_conv_bias_1x1=tf.Variable(tf.zeros([32]))\n",
    "    \n",
    "    \n",
    "    # Fitting blocks\n",
    "    # Parallel sub-modules in Block One\n",
    "    b1_conv1_1x1=convolution(layer,b1_conv_weight_1x1_1,b1_conv_bias_1x1_1)\n",
    "    b1_conv2_1x1=relu(convolution(layer,b1_conv_weight_1x1_2,b1_conv_bias_1x1_2))\n",
    "    b1_conv3_1x1=relu(convolution(layer,b1_conv_weight_1x1_3,b1_conv_bias_1x1_2))\n",
    "    b1_maxpool_3x3=maxpool_3x3(layer)\n",
    "    \n",
    "    # Parallel sub-modules in Block Two\n",
    "    # 3*3 convolution connected to the second 1*1 convolution in Block One\n",
    "    b2_conv1_3x3=convolution(b1_conv2_1x1,b2_conv_weight_3x3,b2_conv_weight_3x3)\n",
    "    # 5*5 convolution connected to the third 1*1 convolution in Block One\n",
    "    b2_conv1_5x5=convolution(b1_conv3_1x1,b2_conv_weight_5x5,b2_conv_bias_5x5)\n",
    "    # 1*1 convolution connected to the max pool layer in Block One\n",
    "    b2_conv1_1x1=convolution(b1_maxpool_3x3,b2_conv_weight_1x1,b2_conv_bias_1x1)\n",
    "    \n",
    "    # Concatenating modules b1_conv1_1x1 in Block One and all the modules in Block Two\n",
    "    b3_concat=tf.concat([b1_conv1_1x1,b2_conv1_3x3,b2_conv1_3x3,b3_conv1_5x5,b2_conv1_1x1],3)\n",
    "    \n",
    "    inception=relu(b3_concat)\n",
    "    \n",
    "    return inception\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
